{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Python analysis extensions
",
    "%matplotlib inline
",
    "import numpy as np
",
    "import pandas as pd
",
    "import scipy
",
    "import datetime as dt
",
    "import sidetable
",
    "import missingno as msno
",
    "#from OSMPythonTools.api import Api
",
    "
",
    "#Graphing and Visual tools
",
    "import plotly.express as px
",
    "#import chart_studio.plotly as py
",
    "import plotly.graph_objs as go
",
    "from plotly.subplots import make_subplots
",
    "
",
    "#GeoSpacial Analysis Tools
",
    "#import contextily as ctx
",
    "from itertools import product
",
    "
",
    "import geopandas as gpd
",
    "from shapely.geometry import Point, Polygon
",
    "from geopy.geocoders import GoogleV3
",
    "import matplotlib.pyplot as plt
",
    "from shapely import geos, wkb, wkt
",
    "import seaborn as sns
",
    "from sqlalchemy import create_engine, text
",
    "sns.set(style=\"darkgrid\")
",
    "%matplotlib inline
",
    "#%load_ext sql
",
    "import statsmodels.api as sm
",
    "import statsmodels.formula.api as smf
",
    "from ydata_profiling import ProfileReport
",
    "import pyreadstat
",
    "from contextlib import contextmanager
",
    "import time
",
    "import numpy as np
",
    "import uuid
",
    "import psycopg2
",
    "from IPython.display import display
",
    "import icecream as ic
",
    "#Jupyter Interactive Widget Extension
",
    "#import ipywidgets as widgets
",
    "#from ipywidgets import interact, interact_manual
",
    "
",
    "#from pandas.io.formats.style import Styler
",
    "#import googlemaps
",
    "pd.options.display.float_format = \"{:.2f}\".format
",
    "import warnings
",
    "from run_plate_cleaner import clean_all_plates_batch
",
    "
",
    "# Enable Plotly in Jupyter Lab
",
    "import plotly.io as pio
",
    "pio.renderers.default = \"notebook\"
",
    "
",
    "# Set display options
",
    "pd.set_option(\"display.max_columns\", None)
",
    "pd.set_option(\"display.width\", 1000)
",
    "pd.set_option(\"display.max_rows\", 50)
",
    "pd.options.display.float_format = \"{:.2f}\".format
",
    "
",
    "# Ignore warnings
",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LISWMC Weigh Events Analytics Dashboard
",
    "
",
    "This notebook provides comprehensive analytics for waste collection events at the Lusaka Integrated Solid Waste Management Company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the data
",
    "weigh_events_file = \"extracted_weigh_events.csv\"
",
    "vehicles_file = \"extracted_vehicles.csv\"
",
    "companies_file = \"extracted_companies.csv\"
",
    "
",
    "# Check if files exist and load them
",
    "files = {
",
    "    \"weigh_events\": weigh_events_file,
",
    "    \"vehicles\": vehicles_file,
",
    "    \"companies\": companies_file
",
    "}
",
    "
",
    "dfs = {}
",
    "
",
    "for name, file in files.items():
",
    "    if os.path.exists(file):
",
    "        print(f\"Loading {name} from {file}...\")
",
    "        dfs[name] = pd.read_csv(file)
",
    "        print(f\"✓ Loaded {len(dfs[name])} rows with {len(dfs[name].columns)} columns\")
",
    "    else:
",
    "        print(f\"✗ File not found: {file}\")
",
    "        dfs[name] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data preprocessing function
",
    "def preprocess_data(weigh_df, vehicles_df, companies_df):
",
    "    # Convert event_time to datetime
",
    "    weigh_df[\"event_time\"] = pd.to_datetime(weigh_df[\"event_time\"])
",
    "    
",
    "    # Extract date components
",
    "    weigh_df[\"date\"] = weigh_df[\"event_time\"].dt.date
",
    "    weigh_df[\"day\"] = weigh_df[\"event_time\"].dt.day
",
    "    weigh_df[\"month\"] = weigh_df[\"event_time\"].dt.month
",
    "    weigh_df[\"month_name\"] = weigh_df[\"event_time\"].dt.month_name()
",
    "    weigh_df[\"year\"] = weigh_df[\"event_time\"].dt.year
",
    "    weigh_df[\"day_of_week\"] = weigh_df[\"event_time\"].dt.day_name()
",
    "    weigh_df[\"day_of_week_num\"] = weigh_df[\"event_time\"].dt.dayofweek
",
    "    weigh_df[\"hour\"] = weigh_df[\"event_time\"].dt.hour
",
    "    weigh_df[\"week\"] = weigh_df[\"event_time\"].dt.isocalendar().week
",
    "    
",
    "    # Map event types
",
    "    event_type_map = {1: \"Entry (Gross Weight)\", 2: \"Exit (Tare Weight)\"}
",
    "    weigh_df[\"event_type_name\"] = weigh_df[\"event_type\"].map(event_type_map)
",
    "    
",
    "    # Add delivery type (normal vs recycle)
",
    "    # Recycle events have \"R\" in the remarks, normal events have location names
",
    "    weigh_df[\"is_recycle\"] = weigh_df[\"remarks\"].str.contains(\"R\", case=False, na=False)
",
    "    weigh_df[\"delivery_type\"] = weigh_df[\"is_recycle\"].map({True: \"Recycle Collection\", False: \"Normal Disposal\"})
",
    "    
",
    "    # Merge with vehicle and company data
",
    "    try:
",
    "        merged_df = weigh_df.merge(vehicles_df, on=\"vehicle_id\", how=\"left\")
",
    "        if \"company_id_x\" in merged_df.columns and \"company_id_y\" in merged_df.columns:
",
    "            # Handle case where company_id appears in both tables
",
    "            merged_df = merged_df.rename(columns={\"company_id_x\": \"company_id\"})
",
    "            merged_df = merged_df.drop(columns=[\"company_id_y\"])
",
    "        
",
    "        # Check if name column exists in companies_df
",
    "        if \"name\" in companies_df.columns:
",
    "            merged_df = merged_df.merge(companies_df[[\"company_id\", \"name\"]], on=\"company_id\", how=\"left\")
",
    "            merged_df.rename(columns={\"name\": \"company_name\"}, inplace=True)
",
    "        else:
",
    "            # Add placeholder for company_name
",
    "            merged_df[\"company_name\"] = \"Unknown\"
",
    "    except Exception as e:
",
    "        print(f\"Error during merge: {e}\")
",
    "        # Create basic merged_df without joins
",
    "        merged_df = weigh_df.copy()
",
    "        merged_df[\"company_name\"] = \"Unknown\"
",
    "    
",
    "    return merged_df
",
    "
",
    "# Calculate net weights for entry-exit pairs
",
    "def calculate_net_weights(df):
",
    "    # Group by session_id
",
    "    sessions = df.groupby(\"session_id\")
",
    "    
",
    "    results = []
",
    "    
",
    "    for session_id, group in sessions:
",
    "        if len(group) >= 2:  # Need at least entry and exit
",
    "            # Sort by event_time to get entry first, exit second
",
    "            group = group.sort_values(\"event_time\")
",
    "            
",
    "            # Get entry and exit weights
",
    "            entry = group[group[\"event_type\"] == 1]
",
    "            exit = group[group[\"event_type\"] == 2]
",
    "            
",
    "            if not entry.empty and not exit.empty:
",
    "                entry_row = entry.iloc[0]
",
    "                exit_row = exit.iloc[0]
",
    "                
",
    "                # Calculate net weight based on delivery type
",
    "                is_recycle = entry_row.get(\"is_recycle\", False)
",
    "                
",
    "                if is_recycle:
",
    "                    # For recycle events, exit weight is higher than entry weight
",
    "                    # They collect recyclables, so net_weight should be positive
",
    "                    gross_weight = exit_row[\"weight_kg\"]
",
    "                    tare_weight = entry_row[\"weight_kg\"]
",
    "                    if gross_weight <= tare_weight:
",
    "                        # Skip invalid data where the pattern doesn\"t match
",
    "                        continue
",
    "                else:
",
    "                    # For normal events, entry weight is higher than exit weight
",
    "                    # They drop off waste, so net_weight should be positive
",
    "                    gross_weight = entry_row[\"weight_kg\"]
",
    "                    tare_weight = exit_row[\"weight_kg\"]
",
    "                    if gross_weight <= tare_weight:
",
    "                        # Skip invalid data where the pattern doesn\"t match
",
    "                        continue
",
    "                
",
    "                # Calculate the absolute difference for net weight
",
    "                net_weight = abs(gross_weight - tare_weight)
",
    "                
",
    "                result = {
",
    "                    \"session_id\": session_id,
",
    "                    \"vehicle_id\": entry_row[\"vehicle_id\"],
",
    "                    \"company_id\": entry_row[\"company_id\"],
",
    "                    \"company_name\": entry_row.get(\"company_name\", \"Unknown\"),
",
    "                    \"license_plate\": entry_row.get(\"license_plate\", \"Unknown\"),
",
    "                    \"entry_time\": entry_row[\"event_time\"],
",
    "                    \"exit_time\": exit_row[\"event_time\"],
",
    "                    \"duration_minutes\": (exit_row[\"event_time\"] - entry_row[\"event_time\"]).total_seconds() / 60,
",
    "                    \"entry_weight\": entry_row[\"weight_kg\"],
",
    "                    \"exit_weight\": exit_row[\"weight_kg\"],
",
    "                    \"net_weight\": net_weight,
",
    "                    \"is_recycle\": is_recycle,
",
    "                    \"delivery_type\": entry_row.get(\"delivery_type\", \"Normal Disposal\"),
",
    "                    \"date\": entry_row[\"date\"],
",
    "                    \"day\": entry_row[\"day\"],
",
    "                    \"month\": entry_row[\"month\"],
",
    "                    \"month_name\": entry_row[\"month_name\"],
",
    "                    \"year\": entry_row[\"year\"],
",
    "                    \"day_of_week\": entry_row[\"day_of_week\"],
",
    "                    \"day_of_week_num\": entry_row[\"day_of_week_num\"],
",
    "                    \"hour\": entry_row[\"hour\"],
",
    "                    \"week\": entry_row[\"week\"],
",
    "                    \"location\": entry_row[\"remarks\"] if not is_recycle else \"Recycle Collection\"
",
    "                }
",
    "                
",
    "                results.append(result)
",
    "    
",
    "    if results:
",
    "        net_weights_df = pd.DataFrame(results)
",
    "        return net_weights_df
",
    "    return pd.DataFrame()
",
    "
",
    "# Process data if available
",
    "if all(df is not None for df in dfs.values()):
",
    "    # Preprocess the data
",
    "    processed_df = preprocess_data(dfs[\"weigh_events\"], dfs[\"vehicles\"], dfs[\"companies\"])
",
    "    print(f\"\nPreprocessed data: {len(processed_df)} rows\")
",
    "    
",
    "    # Calculate net weights
",
    "    net_weights_df = calculate_net_weights(processed_df)
",
    "    print(f\"Paired sessions (entry/exit): {len(net_weights_df)} rows\")
",
    "    
",
    "    # Show data sample
",
    "    print(\"\nSample of processed data:\")
",
    "    display(net_weights_df.head())
",
    "else:
",
    "    print(\"\nCannot process data because some files are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate basic statistics
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Overall statistics
",
    "    total_sessions = len(net_weights_df)
",
    "    total_waste_kg = net_weights_df[\"net_weight\"].sum()
",
    "    total_waste_tons = total_waste_kg / 1000
",
    "    avg_weight_kg = net_weights_df[\"net_weight\"].mean()
",
    "    median_weight_kg = net_weights_df[\"net_weight\"].median()
",
    "    max_weight_kg = net_weights_df[\"net_weight\"].max()
",
    "    min_weight_kg = net_weights_df[\"net_weight\"].min()
",
    "    avg_duration_min = net_weights_df[\"duration_minutes\"].mean()
",
    "    
",
    "    # Count by delivery type
",
    "    normal_sessions = len(net_weights_df[~net_weights_df[\"is_recycle\"]])
",
    "    recycle_sessions = len(net_weights_df[net_weights_df[\"is_recycle\"]])
",
    "    normal_waste_tons = net_weights_df[~net_weights_df[\"is_recycle\"]][\"net_weight\"].sum() / 1000
",
    "    recycle_waste_tons = net_weights_df[net_weights_df[\"is_recycle\"]][\"net_weight\"].sum() / 1000
",
    "    
",
    "    # Format statistics in a nice HTML table
",
    "    stats_html = f\"\"\"
",
    "    <div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;\">
",
    "        <h3 style=\"margin-top: 0;\">Overall Statistics</h3>
",
    "        <table>
",
    "            <tr>
",
    "                <td style=\"padding-right: 20px;\"><strong>Total Sessions:</strong></td>
",
    "                <td>{total_sessions:,}</td>
",
    "                <td style=\"padding-left: 40px;\"><strong>Total Waste:</strong></td>
",
    "                <td>{total_waste_tons:,.2f} tons</td>
",
    "            </tr>
",
    "            <tr>
",
    "                <td><strong>Normal Disposal:</strong></td>
",
    "                <td>{normal_sessions:,} sessions</td>
",
    "                <td style=\"padding-left: 40px;\"><strong>Normal Waste:</strong></td>
",
    "                <td>{normal_waste_tons:,.2f} tons</td>
",
    "            </tr>
",
    "            <tr>
",
    "                <td><strong>Recycle Collection:</strong></td>
",
    "                <td>{recycle_sessions:,} sessions</td>
",
    "                <td style=\"padding-left: 40px;\"><strong>Recycled Material:</strong></td>
",
    "                <td>{recycle_waste_tons:,.2f} tons</td>
",
    "            </tr>
",
    "            <tr>
",
    "                <td><strong>Average Load:</strong></td>
",
    "                <td>{avg_weight_kg:,.2f} kg</td>
",
    "                <td style=\"padding-left: 40px;\"><strong>Median Load:</strong></td>
",
    "                <td>{median_weight_kg:,.2f} kg</td>
",
    "            </tr>
",
    "            <tr>
",
    "                <td><strong>Maximum Load:</strong></td>
",
    "                <td>{max_weight_kg:,.2f} kg</td>
",
    "                <td style=\"padding-left: 40px;\"><strong>Minimum Load:</strong></td>
",
    "                <td>{min_weight_kg:,.2f} kg</td>
",
    "            </tr>
",
    "            <tr>
",
    "                <td><strong>Average Duration:</strong></td>
",
    "                <td>{avg_duration_min:,.2f} minutes</td>
",
    "                <td style=\"padding-left: 40px;\"><strong>Date Range:</strong></td>
",
    "                <td>{net_weights_df[\"entry_time\"].min().strftime(\"%Y-%m-%d\")} to {net_weights_df[\"entry_time\"].max().strftime(\"%Y-%m-%d\")}</td>
",
    "            </tr>
",
    "        </table>
",
    "    </div>
",
    "    \"\"\"
",
    "    
",
    "    display(HTML(stats_html))
",
    "    
",
    "    # Show descriptive statistics of key columns
",
    "    print(\"\nDescriptive statistics of key metrics:\")
",
    "    stats_df = net_weights_df[[\"net_weight\", \"duration_minutes\", \"entry_weight\", \"exit_weight\"]].describe()
",
    "    display(stats_df)
",
    "else:
",
    "    print(\"No processed data available for statistics calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Time series analysis
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Create trend by day
",
    "    daily_data = net_weights_df.groupby([\"date\", \"is_recycle\"]).agg({
",
    "        \"net_weight\": \"sum\",
",
    "        \"session_id\": \"count\"
",
    "    }).reset_index()
",
    "    
",
    "    # Split by delivery type
",
    "    normal_daily = daily_data[~daily_data[\"is_recycle\"]]
",
    "    recycle_daily = daily_data[daily_data[\"is_recycle\"]]
",
    "    
",
    "    # Create time series plot
",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1,
",
    "                       subplot_titles=(\"Daily Waste Collection (tons)\", \"Daily Number of Sessions\"))
",
    "    
",
    "    # Add normal disposal weight trend
",
    "    fig.add_trace(
",
    "        go.Scatter(x=normal_daily[\"date\"], y=normal_daily[\"net_weight\"]/1000,
",
    "                  mode=\"lines\", name=\"Normal Disposal Weight\",
",
    "                  line=dict(color=\"#1f77b4\", width=2)),
",
    "        row=1, col=1
",
    "    )
",
    "    
",
    "    # Add recycle collection weight trend
",
    "    if not recycle_daily.empty:
",
    "        fig.add_trace(
",
    "            go.Scatter(x=recycle_daily[\"date\"], y=recycle_daily[\"net_weight\"]/1000,
",
    "                      mode=\"lines\", name=\"Recycle Collection Weight\",
",
    "                      line=dict(color=\"#2ca02c\", width=2)),
",
    "            row=1, col=1
",
    "        )
",
    "    
",
    "    # Add normal disposal session count
",
    "    fig.add_trace(
",
    "        go.Scatter(x=normal_daily[\"date\"], y=normal_daily[\"session_id\"],
",
    "                  mode=\"lines\", name=\"Normal Sessions\",
",
    "                  line=dict(color=\"#1f77b4\", width=2)),
",
    "        row=2, col=1
",
    "    )
",
    "    
",
    "    # Add recycle collection session count
",
    "    if not recycle_daily.empty:
",
    "        fig.add_trace(
",
    "            go.Scatter(x=recycle_daily[\"date\"], y=recycle_daily[\"session_id\"],
",
    "                      mode=\"lines\", name=\"Recycle Sessions\",
",
    "                      line=dict(color=\"#2ca02c\", width=2)),
",
    "            row=2, col=1
",
    "        )
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        height=600,
",
    "        title_text=\"Waste Collection Time Series Analysis\",
",
    "        hovermode=\"x unified\",
",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)
",
    "    )
",
    "    
",
    "    fig.update_yaxes(title_text=\"Weight (tons)\", row=1, col=1)
",
    "    fig.update_yaxes(title_text=\"Number of Sessions\", row=2, col=1)
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Monthly trend analysis
",
    "    monthly_data = net_weights_df.groupby([\"year\", \"month\", \"month_name\", \"is_recycle\"]).agg({
",
    "        \"net_weight\": \"sum\",
",
    "        \"session_id\": \"count\"
",
    "    }).reset_index()
",
    "    
",
    "    # Create month-year string for better display
",
    "    monthly_data[\"month_year\"] = monthly_data[\"month_name\"] + \" \" + monthly_data[\"year\"].astype(str)
",
    "    
",
    "    # Split by delivery type
",
    "    normal_monthly = monthly_data[~monthly_data[\"is_recycle\"]]
",
    "    recycle_monthly = monthly_data[monthly_data[\"is_recycle\"]]
",
    "    
",
    "    # Sort by year and month
",
    "    normal_monthly = normal_monthly.sort_values([\"year\", \"month\"])
",
    "    if not recycle_monthly.empty:
",
    "        recycle_monthly = recycle_monthly.sort_values([\"year\", \"month\"])
",
    "    
",
    "    # Create monthly trend plot
",
    "    fig = go.Figure()
",
    "    
",
    "    # Add normal disposal
",
    "    fig.add_trace(go.Bar(
",
    "        x=normal_monthly[\"month_year\"],
",
    "        y=normal_monthly[\"net_weight\"]/1000,
",
    "        name=\"Normal Disposal\",
",
    "        marker_color=\"#1f77b4\"
",
    "    ))
",
    "    
",
    "    # Add recycle collection
",
    "    if not recycle_monthly.empty:
",
    "        fig.add_trace(go.Bar(
",
    "            x=recycle_monthly[\"month_year\"],
",
    "            y=recycle_monthly[\"net_weight\"]/1000,
",
    "            name=\"Recycle Collection\",
",
    "            marker_color=\"#2ca02c\"
",
    "        ))
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        title=\"Monthly Waste Collection Trend\",
",
    "        xaxis_title=None,
",
    "        yaxis_title=\"Weight (tons)\",
",
    "        barmode=\"group\",
",
    "        xaxis={\"categoryorder\": \"array\", \"categoryarray\": normal_monthly[\"month_year\"].tolist()},
",
    "        height=500
",
    "    )
",
    "    
",
    "    # Rotate x-axis labels for better readability
",
    "    fig.update_xaxes(tickangle=45)
",
    "    
",
    "    fig.show()
",
    "else:
",
    "    print(\"No processed data available for time series analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day of Week Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Day of week analysis
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Prepare day of week data
",
    "    day_data = net_weights_df.groupby([\"day_of_week\", \"day_of_week_num\", \"is_recycle\"]).agg({
",
    "        \"net_weight\": [\"sum\", \"mean\"],
",
    "        \"session_id\": \"count\"
",
    "    }).reset_index()
",
    "    
",
    "    # Flatten multi-level columns
",
    "    day_data.columns = [\"day_of_week\", \"day_of_week_num\", \"is_recycle\", \"total_weight\", \"avg_weight\", \"session_count\"]
",
    "    
",
    "    # Sort by day of week
",
    "    day_data = day_data.sort_values(\"day_of_week_num\")
",
    "    
",
    "    # Create plot
",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Total Weight by Day of Week\", \"Average Weight by Day of Week\"), 
",
    "                       specs=[[{\"secondary_y\": True}, {\"secondary_y\": True}]])
",
    "    
",
    "    # Split by delivery type
",
    "    normal_day = day_data[~day_data[\"is_recycle\"]]
",
    "    recycle_day = day_data[day_data[\"is_recycle\"]]
",
    "    
",
    "    # Total weight - Normal
",
    "    fig.add_trace(
",
    "        go.Bar(x=normal_day[\"day_of_week\"], y=normal_day[\"total_weight\"]/1000,
",
    "               name=\"Normal Disposal\", marker_color=\"#1f77b4\", offsetgroup=0),
",
    "        row=1, col=1, secondary_y=False
",
    "    )
",
    "    
",
    "    # Total weight - Recycle
",
    "    if not recycle_day.empty:
",
    "        fig.add_trace(
",
    "            go.Bar(x=recycle_day[\"day_of_week\"], y=recycle_day[\"total_weight\"]/1000,
",
    "                   name=\"Recycle Collection\", marker_color=\"#2ca02c\", offsetgroup=1),
",
    "            row=1, col=1, secondary_y=False
",
    "        )
",
    "    
",
    "    # Session count - Normal
",
    "    fig.add_trace(
",
    "        go.Scatter(x=normal_day[\"day_of_week\"], y=normal_day[\"session_count\"],
",
    "                    mode=\"lines+markers\", name=\"Normal Sessions\", line=dict(color=\"#ff7f0e\")),
",
    "        row=1, col=1, secondary_y=True
",
    "    )
",
    "    
",
    "    # Session count - Recycle
",
    "    if not recycle_day.empty:
",
    "        fig.add_trace(
",
    "            go.Scatter(x=recycle_day[\"day_of_week\"], y=recycle_day[\"session_count\"],
",
    "                        mode=\"lines+markers\", name=\"Recycle Sessions\", line=dict(color=\"#d62728\")),
",
    "            row=1, col=1, secondary_y=True
",
    "        )
",
    "    
",
    "    # Average weight - Normal
",
    "    fig.add_trace(
",
    "        go.Bar(x=normal_day[\"day_of_week\"], y=normal_day[\"avg_weight\"],
",
    "               name=\"Avg Normal\", marker_color=\"#1f77b4\", offsetgroup=0,
",
    "               showlegend=False),
",
    "        row=1, col=2, secondary_y=False
",
    "    )
",
    "    
",
    "    # Average weight - Recycle
",
    "    if not recycle_day.empty:
",
    "        fig.add_trace(
",
    "            go.Bar(x=recycle_day[\"day_of_week\"], y=recycle_day[\"avg_weight\"],
",
    "                   name=\"Avg Recycle\", marker_color=\"#2ca02c\", offsetgroup=1,
",
    "                   showlegend=False),
",
    "            row=1, col=2, secondary_y=False
",
    "        )
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        title_text=\"Waste Collection by Day of Week\",
",
    "        height=500,
",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)
",
    "    )
",
    "    
",
    "    # Update y-axis titles
",
    "    fig.update_yaxes(title_text=\"Weight (tons)\", row=1, col=1, secondary_y=False)
",
    "    fig.update_yaxes(title_text=\"Sessions\", row=1, col=1, secondary_y=True)
",
    "    fig.update_yaxes(title_text=\"Average Weight (kg)\", row=1, col=2, secondary_y=False)
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Create hourly heatmap by day of week
",
    "    hour_data = net_weights_df.groupby([\"day_of_week\", \"day_of_week_num\", \"hour\"]).size().reset_index(name=\"count\")
",
    "    
",
    "    # Sort by day of week
",
    "    hour_data = hour_data.sort_values([\"day_of_week_num\", \"hour\"])
",
    "    
",
    "    # Create pivot table
",
    "    pivot_data = hour_data.pivot(index=\"day_of_week\", columns=\"hour\", values=\"count\")
",
    "    
",
    "    # Define day order
",
    "    day_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]
",
    "    pivot_data = pivot_data.reindex(day_order)
",
    "    
",
    "    # Create heatmap
",
    "    fig = px.imshow(pivot_data, 
",
    "                   labels=dict(x=\"Hour of Day\", y=\"Day of Week\", color=\"Sessions\"),
",
    "                   x=pivot_data.columns, 
",
    "                   y=pivot_data.index,
",
    "                   color_continuous_scale=\"Blues\",
",
    "                   aspect=\"auto\")
",
    "    
",
    "    fig.update_layout(
",
    "        title=\"Activity Heatmap by Day and Hour\",
",
    "        xaxis=dict(tickmode=\"linear\", dtick=1, tickfont=dict(size=10)),
",
    "        height=400
",
    "    )
",
    "    
",
    "    fig.show()
",
    "else:
",
    "    print(\"No processed data available for day of week analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Location analysis
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Filter to normal disposal (not recycle) and drop legacy data
",
    "    normal_df = net_weights_df[~net_weights_df[\"is_recycle\"]]
",
    "    location_df = normal_df[~normal_df[\"location\"].isin([\"LEGACY DATA\", \"\"])]
",
    "    
",
    "    # Group by location
",
    "    location_data = location_df.groupby(\"location\").agg({
",
    "        \"net_weight\": [\"sum\", \"mean\", \"count\"]
",
    "    }).reset_index()
",
    "    
",
    "    # Flatten multi-level columns
",
    "    location_data.columns = [\"location\", \"total_weight\", \"avg_weight\", \"session_count\"]
",
    "    
",
    "    # Sort by total weight
",
    "    location_data = location_data.sort_values(\"total_weight\", ascending=False)
",
    "    
",
    "    # Get top 15 locations
",
    "    top_locations = location_data.head(15)
",
    "    
",
    "    # Create horizontal bar chart
",
    "    fig = go.Figure()
",
    "    
",
    "    # Add bar for total weight
",
    "    fig.add_trace(go.Bar(
",
    "        y=top_locations[\"location\"],
",
    "        x=top_locations[\"total_weight\"]/1000,
",
    "        orientation=\"h\",
",
    "        name=\"Total Weight (tons)\",
",
    "        marker_color=\"#1f77b4\"
",
    "    ))
",
    "    
",
    "    # Add scatter for session count
",
    "    fig.add_trace(go.Scatter(
",
    "        y=top_locations[\"location\"],
",
    "        x=top_locations[\"session_count\"],
",
    "        mode=\"markers\",
",
    "        name=\"Number of Sessions\",
",
    "        marker=dict(color=\"#ff7f0e\", size=top_locations[\"session_count\"]/top_locations[\"session_count\"].max()*30+5)
",
    "    ))
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        title=\"Top 15 Locations by Waste Volume\",
",
    "        xaxis_title=\"Weight (tons)\",
",
    "        yaxis_title=None,
",
    "        height=600,
",
    "        barmode=\"group\",
",
    "        yaxis={\"categoryorder\": \"total ascending\"}
",
    "    )
",
    "    
",
    "    # Add secondary x-axis for session count
",
    "    fig.update_layout(
",
    "        xaxis2=dict(
",
    "            title=\"Number of Sessions\",
",
    "            overlaying=\"x\",
",
    "            side=\"top\",
",
    "            range=[0, top_locations[\"session_count\"].max()*1.1]
",
    "        )
",
    "    )
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Create average weight by location chart
",
    "    fig = px.bar(
",
    "        top_locations,
",
    "        x=\"location\",
",
    "        y=\"avg_weight\",
",
    "        color=\"total_weight\",
",
    "        color_continuous_scale=\"Blues\",
",
    "        labels={
",
    "            \"location\": \"Location\",
",
    "            \"avg_weight\": \"Average Weight (kg)\",
",
    "            \"total_weight\": \"Total Weight (kg)\"
",
    "        },
",
    "        height=500
",
    "    )
",
    "    
",
    "    fig.update_layout(
",
    "        title=\"Average Load Weight by Location\",
",
    "        xaxis_title=None,
",
    "        xaxis_tickangle=45
",
    "    )
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Create trend for top 5 locations
",
    "    top5_locations = location_data.head(5)[\"location\"].tolist()
",
    "    top5_df = location_df[location_df[\"location\"].isin(top5_locations)]
",
    "    
",
    "    # Group by location and date
",
    "    top5_daily = top5_df.groupby([\"location\", \"date\"]).agg({
",
    "        \"net_weight\": \"sum\"
",
    "    }).reset_index()
",
    "    
",
    "    # Create line chart
",
    "    fig = px.line(
",
    "        top5_daily, 
",
    "        x=\"date\", 
",
    "        y=\"net_weight\",
",
    "        color=\"location\",
",
    "        labels={
",
    "            \"date\": \"Date\",
",
    "            \"net_weight\": \"Weight (kg)\",
",
    "            \"location\": \"Location\"
",
    "        },
",
    "        height=500
",
    "    )
",
    "    
",
    "    fig.update_layout(
",
    "        title=\"Top 5 Locations Trend Over Time\",
",
    "        xaxis_title=None,
",
    "        yaxis_title=\"Weight (kg)\"
",
    "    )
",
    "    
",
    "    fig.show()
",
    "else:
",
    "    print(\"No processed data available for location analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle and Company Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Vehicle and company analysis
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Analyze by vehicle
",
    "    vehicle_data = net_weights_df.groupby([\"license_plate\", \"is_recycle\"]).agg({
",
    "        \"net_weight\": [\"sum\", \"mean\"],
",
    "        \"session_id\": \"count\",
",
    "        \"duration_minutes\": \"mean\"
",
    "    }).reset_index()
",
    "    
",
    "    # Flatten multi-level columns
",
    "    vehicle_data.columns = [\"license_plate\", \"is_recycle\", \"total_weight\", \"avg_weight\", \"session_count\", \"avg_duration\"]
",
    "    
",
    "    # Get top vehicles overall
",
    "    top_vehicles = vehicle_data.sort_values(\"total_weight\", ascending=False).head(10)
",
    "    
",
    "    # Create bar chart
",
    "    fig = px.bar(
",
    "        top_vehicles,
",
    "        x=\"license_plate\",
",
    "        y=\"total_weight\",
",
    "        color=\"is_recycle\",
",
    "        color_discrete_map={False: \"#1f77b4\", True: \"#2ca02c\"},
",
    "        labels={
",
    "            \"license_plate\": \"Vehicle\",
",
    "            \"total_weight\": \"Total Weight (kg)\",
",
    "            \"is_recycle\": \"Type\"
",
    "        },
",
    "        height=500,
",
    "        text=\"session_count\"
",
    "    )
",
    "    
",
    "    # Update traces to show session count
",
    "    fig.update_traces(texttemplate=\"%{text} sessions\", textposition=\"outside\")
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        title=\"Top 10 Vehicles by Total Waste Volume\",
",
    "        xaxis_title=None,
",
    "        yaxis_title=\"Weight (kg)\",
",
    "        xaxis={\"categoryorder\": \"total descending\"},
",
    "        legend_title=None
",
    "    )
",
    "    
",
    "    # Update legend labels
",
    "    fig.for_each_trace(lambda t: t.update(
",
    "        name=\"Recycle Collection\" if t.name == \"True\" else \"Normal Disposal\"
",
    "    ))
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Company analysis
",
    "    if \"company_name\" in net_weights_df.columns:
",
    "        company_data = net_weights_df.groupby([\"company_name\", \"is_recycle\"]).agg({
",
    "            \"net_weight\": [\"sum\", \"mean\"],
",
    "            \"session_id\": \"count\"
",
    "        }).reset_index()
",
    "        
",
    "        # Flatten multi-level columns
",
    "        company_data.columns = [\"company_name\", \"is_recycle\", \"total_weight\", \"avg_weight\", \"session_count\"]
",
    "        
",
    "        # Get top companies by total weight
",
    "        top_companies = company_data.sort_values(\"total_weight\", ascending=False).head(10)
",
    "        
",
    "        # Get company names and IDs as text to display (first 20 characters only)
",
    "        top_companies[\"company_display\"] = top_companies[\"company_name\"].str.slice(0, 25) + \"...\"
",
    "        
",
    "        # Create bar chart
",
    "        fig = px.bar(
",
    "            top_companies,
",
    "            x=\"company_display\",
",
    "            y=\"total_weight\",
",
    "            color=\"is_recycle\",
",
    "            color_discrete_map={False: \"#1f77b4\", True: \"#2ca02c\"},
",
    "            labels={
",
    "                \"company_display\": \"Company\",
",
    "                \"total_weight\": \"Total Weight (kg)\",
",
    "                \"is_recycle\": \"Type\"
",
    "            },
",
    "            height=500,
",
    "            text=\"session_count\",
",
    "            hover_data=[\"company_name\"]
",
    "        )
",
    "        
",
    "        # Update traces to show session count
",
    "        fig.update_traces(texttemplate=\"%{text} sessions\", textposition=\"outside\")
",
    "        
",
    "        # Update layout
",
    "        fig.update_layout(
",
    "            title=\"Top 10 Companies by Total Waste Volume\",
",
    "            xaxis_title=None,
",
    "            yaxis_title=\"Weight (kg)\",
",
    "            xaxis={\"categoryorder\": \"total descending\", \"tickangle\": 45},
",
    "            legend_title=None
",
    "        )
",
    "        
",
    "        # Update legend labels
",
    "        fig.for_each_trace(lambda t: t.update(
",
    "            name=\"Recycle Collection\" if t.name == \"True\" else \"Normal Disposal\"
",
    "        ))
",
    "        
",
    "        fig.show()
",
    "else:
",
    "    print(\"No processed data available for vehicle and company analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal vs Recycle Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Normal vs recycle analysis
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Pie chart for proportion
",
    "    delivery_type = net_weights_df.groupby(\"delivery_type\").agg({
",
    "        \"net_weight\": \"sum\",
",
    "        \"session_id\": \"count\"
",
    "    }).reset_index()
",
    "    
",
    "    # Create subplot with two pie charts
",
    "    fig = make_subplots(rows=1, cols=2, specs=[[{\"type\":\"domain\"}, {\"type\":\"domain\"}]],
",
    "                      subplot_titles=(\"Total Weight Distribution\", \"Session Count Distribution\"))
",
    "    
",
    "    # Weight distribution pie chart
",
    "    fig.add_trace(go.Pie(
",
    "        labels=delivery_type[\"delivery_type\"],
",
    "        values=delivery_type[\"net_weight\"],
",
    "        name=\"Weight\",
",
    "        marker_colors=[\"#1f77b4\", \"#2ca02c\"]
",
    "    ), 1, 1)
",
    "    
",
    "    # Session count pie chart
",
    "    fig.add_trace(go.Pie(
",
    "        labels=delivery_type[\"delivery_type\"],
",
    "        values=delivery_type[\"session_id\"],
",
    "        name=\"Sessions\",
",
    "        marker_colors=[\"#1f77b4\", \"#2ca02c\"]
",
    "    ), 1, 2)
",
    "    
",
    "    # Update traces for better display
",
    "    fig.update_traces(hole=0.4, hoverinfo=\"label+percent+name+value\", textinfo=\"percent+value\")
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        title_text=\"Normal Disposal vs Recycle Collection\",
",
    "        annotations=[dict(text=\"Weight\", x=0.18, y=0.5, font_size=14, showarrow=False),
",
    "                     dict(text=\"Sessions\", x=0.82, y=0.5, font_size=14, showarrow=False)]
",
    "    )
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Compare session durations and weights
",
    "    # Create box plots for comparison
",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Net Weight Comparison\", \"Session Duration Comparison\"))
",
    "    
",
    "    # Net weight box plot
",
    "    normal_weights = net_weights_df[~net_weights_df[\"is_recycle\"]][\"net_weight\"]
",
    "    recycle_weights = net_weights_df[net_weights_df[\"is_recycle\"]][\"net_weight\"]
",
    "    
",
    "    fig.add_trace(
",
    "        go.Box(y=normal_weights, name=\"Normal Disposal\", marker_color=\"#1f77b4\"),
",
    "        row=1, col=1
",
    "    )
",
    "    
",
    "    if not recycle_weights.empty:
",
    "        fig.add_trace(
",
    "            go.Box(y=recycle_weights, name=\"Recycle Collection\", marker_color=\"#2ca02c\"),
",
    "            row=1, col=1
",
    "        )
",
    "    
",
    "    # Duration box plot
",
    "    normal_durations = net_weights_df[~net_weights_df[\"is_recycle\"]][\"duration_minutes\"]
",
    "    recycle_durations = net_weights_df[net_weights_df[\"is_recycle\"]][\"duration_minutes\"]
",
    "    
",
    "    fig.add_trace(
",
    "        go.Box(y=normal_durations, name=\"Normal Disposal\", marker_color=\"#1f77b4\", showlegend=False),
",
    "        row=1, col=2
",
    "    )
",
    "    
",
    "    if not recycle_durations.empty:
",
    "        fig.add_trace(
",
    "            go.Box(y=recycle_durations, name=\"Recycle Collection\", marker_color=\"#2ca02c\", showlegend=False),
",
    "            row=1, col=2
",
    "        )
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        title_text=\"Comparing Normal Disposal vs Recycle Collection\",
",
    "        height=500,
",
    "        boxmode=\"group\"
",
    "    )
",
    "    
",
    "    # Update y-axis titles
",
    "    fig.update_yaxes(title_text=\"Weight (kg)\", row=1, col=1)
",
    "    fig.update_yaxes(title_text=\"Duration (minutes)\", row=1, col=2)
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Create scatter plot of entry vs exit weight by delivery type
",
    "    fig = px.scatter(
",
    "        net_weights_df,
",
    "        x=\"entry_weight\",
",
    "        y=\"exit_weight\",
",
    "        color=\"delivery_type\",
",
    "        color_discrete_map={
",
    "            \"Normal Disposal\": \"#1f77b4\",
",
    "            \"Recycle Collection\": \"#2ca02c\"
",
    "        },
",
    "        opacity=0.7,
",
    "        hover_name=\"license_plate\",
",
    "        hover_data=[\"net_weight\", \"duration_minutes\", \"location\"],
",
    "        title=\"Entry vs Exit Weight by Delivery Type\",
",
    "        labels={
",
    "            \"entry_weight\": \"Entry Weight (kg)\",
",
    "            \"exit_weight\": \"Exit Weight (kg)\",
",
    "            \"delivery_type\": \"Delivery Type\"
",
    "        }
",
    "    )
",
    "    
",
    "    # Add a diagonal reference line (entry = exit)
",
    "    min_weight = min(net_weights_df[\"entry_weight\"].min(), net_weights_df[\"exit_weight\"].min())
",
    "    max_weight = max(net_weights_df[\"entry_weight\"].max(), net_weights_df[\"exit_weight\"].max())
",
    "    
",
    "    fig.add_trace(
",
    "        go.Scatter(
",
    "            x=[min_weight, max_weight],
",
    "            y=[min_weight, max_weight],
",
    "            mode=\"lines\",
",
    "            line=dict(color=\"gray\", dash=\"dash\"),
",
    "            name=\"Equal Weight Line\"
",
    "        )
",
    "    )
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        height=600,
",
    "        xaxis_title=\"Entry Weight (kg)\",
",
    "        yaxis_title=\"Exit Weight (kg)\"
",
    "    )
",
    "    
",
    "    fig.show()
",
    "else:
",
    "    print(\"No processed data available for normal vs recycle analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration and Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Duration and efficiency analysis
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Create a new column for weight per minute (efficiency)
",
    "    net_weights_df[\"weight_per_minute\"] = net_weights_df[\"net_weight\"] / net_weights_df[\"duration_minutes\"].replace(0, np.nan)
",
    "    
",
    "    # Scatter plot: Duration vs Weight
",
    "    fig = px.scatter(
",
    "        net_weights_df,
",
    "        x=\"duration_minutes\",
",
    "        y=\"net_weight\",
",
    "        color=\"delivery_type\",
",
    "        color_discrete_map={
",
    "            \"Normal Disposal\": \"#1f77b4\",
",
    "            \"Recycle Collection\": \"#2ca02c\"
",
    "        },
",
    "        size=\"net_weight\",
",
    "        hover_name=\"license_plate\",
",
    "        hover_data=[\"location\", \"entry_time\", \"exit_time\"],
",
    "        opacity=0.7,
",
    "        height=600,
",
    "        title=\"Duration vs Net Weight Analysis\",
",
    "        labels={
",
    "            \"duration_minutes\": \"Duration (minutes)\",
",
    "            \"net_weight\": \"Net Weight (kg)\",
",
    "            \"delivery_type\": \"Delivery Type\"
",
    "        }
",
    "    )
",
    "    
",
    "    # Set reasonable axis limits (removing outliers)
",
    "    fig.update_xaxes(range=[0, net_weights_df[\"duration_minutes\"].quantile(0.95)])
",
    "    fig.update_yaxes(range=[0, net_weights_df[\"net_weight\"].quantile(0.99)])
",
    "    
",
    "    fig.show()
",
    "    
",
    "    # Calculate hourly statistics
",
    "    hourly_data = net_weights_df.groupby([\"hour\", \"is_recycle\"]).agg({
",
    "        \"net_weight\": [\"sum\", \"mean\"],
",
    "        \"duration_minutes\": \"mean\",
",
    "        \"weight_per_minute\": \"mean\",
",
    "        \"session_id\": \"count\"
",
    "    }).reset_index()
",
    "    
",
    "    # Flatten multi-level columns
",
    "    hourly_data.columns = [\"hour\", \"is_recycle\", \"total_weight\", \"avg_weight\", \"avg_duration\", \"avg_efficiency\", \"session_count\"]
",
    "    
",
    "    # Split by delivery type
",
    "    normal_hourly = hourly_data[~hourly_data[\"is_recycle\"]]
",
    "    recycle_hourly = hourly_data[hourly_data[\"is_recycle\"]]
",
    "    
",
    "    # Create hourly efficiency plot
",
    "    fig = make_subplots(rows=1, cols=2, 
",
    "                       subplot_titles=(\"Average Session Duration by Hour\", \"Average Processing Efficiency by Hour\"),
",
    "                       specs=[[{\"secondary_y\": True}, {\"secondary_y\": True}]])
",
    "    
",
    "    # Normal disposal - Duration
",
    "    fig.add_trace(
",
    "        go.Scatter(x=normal_hourly[\"hour\"], y=normal_hourly[\"avg_duration\"],
",
    "                   mode=\"lines+markers\", name=\"Normal - Duration\",
",
    "                   line=dict(color=\"#1f77b4\", width=2)),
",
    "        row=1, col=1, secondary_y=False
",
    "    )
",
    "    
",
    "    # Recycle collection - Duration
",
    "    if not recycle_hourly.empty:
",
    "        fig.add_trace(
",
    "            go.Scatter(x=recycle_hourly[\"hour\"], y=recycle_hourly[\"avg_duration\"],
",
    "                       mode=\"lines+markers\", name=\"Recycle - Duration\",
",
    "                       line=dict(color=\"#2ca02c\", width=2)),
",
    "            row=1, col=1, secondary_y=False
",
    "        )
",
    "    
",
    "    # Session counts
",
    "    fig.add_trace(
",
    "        go.Bar(x=normal_hourly[\"hour\"], y=normal_hourly[\"session_count\"],
",
    "               name=\"Normal Sessions\", marker_color=\"rgba(31, 119, 180, 0.3)\"),
",
    "        row=1, col=1, secondary_y=True
",
    "    )
",
    "    
",
    "    if not recycle_hourly.empty:
",
    "        fig.add_trace(
",
    "            go.Bar(x=recycle_hourly[\"hour\"], y=recycle_hourly[\"session_count\"],
",
    "                   name=\"Recycle Sessions\", marker_color=\"rgba(44, 160, 44, 0.3)\"),
",
    "            row=1, col=1, secondary_y=True
",
    "        )
",
    "    
",
    "    # Normal disposal - Efficiency
",
    "    fig.add_trace(
",
    "        go.Scatter(x=normal_hourly[\"hour\"], y=normal_hourly[\"avg_efficiency\"],
",
    "                   mode=\"lines+markers\", name=\"Normal - Efficiency\",
",
    "                   line=dict(color=\"#1f77b4\", width=2)),
",
    "        row=1, col=2, secondary_y=False
",
    "    )
",
    "    
",
    "    # Recycle collection - Efficiency
",
    "    if not recycle_hourly.empty:
",
    "        fig.add_trace(
",
    "            go.Scatter(x=recycle_hourly[\"hour\"], y=recycle_hourly[\"avg_efficiency\"],
",
    "                       mode=\"lines+markers\", name=\"Recycle - Efficiency\",
",
    "                       line=dict(color=\"#2ca02c\", width=2),
",
    "                       showlegend=False),
",
    "            row=1, col=2, secondary_y=False
",
    "        )
",
    "    
",
    "    # Average weight
",
    "    fig.add_trace(
",
    "        go.Bar(x=normal_hourly[\"hour\"], y=normal_hourly[\"avg_weight\"],
",
    "               name=\"Normal Avg Weight\", marker_color=\"rgba(31, 119, 180, 0.3)\",
",
    "               showlegend=False),
",
    "        row=1, col=2, secondary_y=True
",
    "    )
",
    "    
",
    "    if not recycle_hourly.empty:
",
    "        fig.add_trace(
",
    "            go.Bar(x=recycle_hourly[\"hour\"], y=recycle_hourly[\"avg_weight\"],
",
    "                   name=\"Recycle Avg Weight\", marker_color=\"rgba(44, 160, 44, 0.3)\",
",
    "                   showlegend=False),
",
    "            row=1, col=2, secondary_y=True
",
    "        )
",
    "    
",
    "    # Update layout
",
    "    fig.update_layout(
",
    "        title_text=\"Hourly Efficiency Analysis\",
",
    "        height=500,
",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)
",
    "    )
",
    "    
",
    "    # Update x-axes
",
    "    fig.update_xaxes(title_text=\"Hour of Day\", tickmode=\"linear\", dtick=2, row=1, col=1)
",
    "    fig.update_xaxes(title_text=\"Hour of Day\", tickmode=\"linear\", dtick=2, row=1, col=2)
",
    "    
",
    "    # Update y-axes
",
    "    fig.update_yaxes(title_text=\"Duration (minutes)\", row=1, col=1, secondary_y=False)
",
    "    fig.update_yaxes(title_text=\"Session Count\", row=1, col=1, secondary_y=True)
",
    "    fig.update_yaxes(title_text=\"Efficiency (kg/min)\", row=1, col=2, secondary_y=False)
",
    "    fig.update_yaxes(title_text=\"Average Weight (kg)\", row=1, col=2, secondary_y=True)
",
    "    
",
    "    fig.show()
",
    "else:
",
    "    print(\"No processed data available for duration and efficiency analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Table View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display data table
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    # Select relevant columns
",
    "    display_cols = [
",
    "        \"session_id\", \"license_plate\", \"company_name\", \"location\",
",
    "        \"entry_time\", \"exit_time\", \"duration_minutes\",
",
    "        \"entry_weight\", \"exit_weight\", \"net_weight\", \"delivery_type\"
",
    "    ]
",
    "    
",
    "    # Ensure all columns exist
",
    "    display_cols = [col for col in display_cols if col in net_weights_df.columns]
",
    "    
",
    "    # Format datetime columns
",
    "    table_df = net_weights_df[display_cols].copy()
",
    "    if \"entry_time\" in table_df.columns and \"exit_time\" in table_df.columns:
",
    "        table_df[\"entry_time\"] = pd.to_datetime(table_df[\"entry_time\"]).dt.strftime(\"%Y-%m-%d %H:%M\")
",
    "        table_df[\"exit_time\"] = pd.to_datetime(table_df[\"exit_time\"]).dt.strftime(\"%Y-%m-%d %H:%M\")
",
    "    
",
    "    # Round numeric columns
",
    "    for col in [\"duration_minutes\", \"entry_weight\", \"exit_weight\", \"net_weight\"]:
",
    "        if col in table_df.columns:
",
    "            table_df[col] = table_df[col].round(2)
",
    "    
",
    "    # Display last 20 rows
",
    "    print(f\"\nShowing last 20 of {len(table_df)} records:\")
",
    "    display(table_df.tail(20))
",
    "else:
",
    "    print(\"No processed data available for table view.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save processed data to CSV
",
    "if \"net_weights_df\" in locals() and not net_weights_df.empty:
",
    "    output_file = \"processed_weigh_events.csv\"
",
    "    net_weights_df.to_csv(output_file, index=False)
",
    "    print(f\"\nProcessed data saved to {output_file}\")
",
    "    print(f\"Saved {len(net_weights_df)} rows with {len(net_weights_df.columns)} columns\")
",
    "else:
",
    "    print(\"No processed data available to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
